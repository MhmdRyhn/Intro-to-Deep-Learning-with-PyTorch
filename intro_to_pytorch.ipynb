{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(2000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 2 seconds\n"
     ]
    }
   ],
   "source": [
    "%autosave 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_activation(x):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    ----------\n",
    "    x: torch.Tensor\n",
    "    \"\"\"\n",
    "    return 1/(1+torch.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For single layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features:\n",
      " tensor([[-0.1468,  0.7861,  0.9468, -1.1143,  1.6908]])\n",
      "weights:\n",
      " tensor([[0.2868, 0.2063, 0.4451, 0.3593, 0.7204]])\n",
      "bias:\n",
      " tensor([[0.0731]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(7)\n",
    "\n",
    "# features are 5 random normal variables\n",
    "features = torch.randn((1, 5))\n",
    "print('features:\\n', features)\n",
    "# Same as features' dimension\n",
    "weights = torch.rand_like(features)\n",
    "print('weights:\\n', weights)\n",
    "# Bias term\n",
    "bias = torch.rand((1,1))\n",
    "print('bias:\\n', bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wi_xi = torch.sum(features * weights)\n",
    "# This can also be used\n",
    "# wi_xi = (features * weights).sum()\n",
    "y_hat = sigmoid_activation(wi_xi + bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8072]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For multiple layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(7) # Set the random seed so things are predictable\n",
    "\n",
    "# Features are 3 random normal variables\n",
    "features = torch.randn((1, 3))\n",
    "\n",
    "# Define the size of each layer in our network\n",
    "n_input = features.shape[1]     # Number of input units, must match number of input features\n",
    "n_hidden = 2                    # Number of hidden units \n",
    "n_output = 1                    # Number of output units\n",
    "\n",
    "# Weights for inputs to hidden layer\n",
    "W1 = torch.randn(n_input, n_hidden)\n",
    "# Weights for hidden layer to output layer\n",
    "W2 = torch.randn(n_hidden, n_output)\n",
    "\n",
    "# and bias terms for hidden and output layers\n",
    "B1 = torch.randn((1, n_hidden))\n",
    "B2 = torch.randn((1, n_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3171]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features2 = sigmoid_activation(torch.mm(features, W1) + B1)\n",
    "y_hat = sigmoid_activation(torch.mm(features2, W2) + B2)\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handwritten digit recognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# import helper\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to C:\\Users\\rayhan/.pytorch/MNIST_data/MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.1%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting C:\\Users\\rayhan/.pytorch/MNIST_data/MNIST\\raw\\train-images-idx3-ubyte.gz to C:\\Users\\rayhan/.pytorch/MNIST_data/MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to C:\\Users\\rayhan/.pytorch/MNIST_data/MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "113.5%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting C:\\Users\\rayhan/.pytorch/MNIST_data/MNIST\\raw\\train-labels-idx1-ubyte.gz to C:\\Users\\rayhan/.pytorch/MNIST_data/MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to C:\\Users\\rayhan/.pytorch/MNIST_data/MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.4%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting C:\\Users\\rayhan/.pytorch/MNIST_data/MNIST\\raw\\t10k-images-idx3-ubyte.gz to C:\\Users\\rayhan/.pytorch/MNIST_data/MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to C:\\Users\\rayhan/.pytorch/MNIST_data/MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "180.4%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting C:\\Users\\rayhan/.pytorch/MNIST_data/MNIST\\raw\\t10k-labels-idx1-ubyte.gz to C:\\Users\\rayhan/.pytorch/MNIST_data/MNIST\\raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])\n",
    "\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "print(type(images))\n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2073b8d2dc8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 248,
       "width": 251
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[1].numpy().squeeze(), cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 10])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = images.view(images.shape[0], -1)\n",
    "\n",
    "hidden_units = 256\n",
    "size, input_units = inputs.shape\n",
    "output_units = 10\n",
    "\n",
    "w1 = torch.randn(input_units, hidden_units)\n",
    "# b1 = torch.randn(1, hidden_units)\n",
    "b1 = torch.randn(hidden_units)\n",
    "\n",
    "w2 = torch.randn(hidden_units, output_units)\n",
    "# b2 = torch.randn(1, output_units)\n",
    "b2 = torch.randn(output_units)\n",
    "\n",
    "h = sigmoid_activation(torch.mm(inputs, w1) + b1)\n",
    "output = sigmoid_activation(torch.mm(h, w2) + b2)\n",
    "\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return torch.exp(x)/torch.sum(torch.exp(x), dim=1).view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000])\n"
     ]
    }
   ],
   "source": [
    "probabilities = softmax(output)\n",
    "print(probabilities.shape)\n",
    "# Check for each image that if the summation of all the 10 probabilities is equal to 1\n",
    "print(probabilities.sum(dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building networks with PyTorch (OOP style):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hidden = nn.Linear(in_features=784, out_features=256)\n",
    "        self.output = nn.Linear(in_features=256, out_features=10)\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.hidden(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.output(x)\n",
    "        x = self.siftmax(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another way of building neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (hidden): Linear(in_features=784, out_features=256, bias=True)\n",
       "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hidden = nn.Linear(in_features=784, out_features=256)\n",
    "        self.output = nn.Linear(in_features=256, out_features=10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.sigmoid(self.hidden(x))\n",
    "        x = F.softmax(self.output(x))\n",
    "        return x\n",
    "\n",
    "model = NeuralNetwork()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation Functions\n",
    "So far we've only been looking at the softmax activation, but in general any function can be used as an activation function. The only requirement is that for a network to approximate a non-linear function, **the activation functions must be non-linear**. A few more examples of common activation functions: **Tanh (hyperbolic tangent), and ReLU (rectified linear unit)**. In practice, the **ReLU function is used almost exclusively as the activation function for hidden layers**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (fc_output): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=784, out_features=128)\n",
    "        self.fc2 = nn.Linear(in_features=128, out_features=64)\n",
    "        self.fc_output = nn.Linear(in_features=64, out_features=10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.softmax(self.fc_output(x))\n",
    "        return x\n",
    "\n",
    "model = NeuralNetwork()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building neural network using nn.Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
